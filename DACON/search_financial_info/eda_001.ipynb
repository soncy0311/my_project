{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c61eac-af01-4a58-b219-c4237c221221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soncy/miniconda3/envs/daycon/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/soncy/miniconda3/envs/daycon/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import fitz\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd8692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/soncy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff1f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_pdf(path:Path) :\n",
    "    # 한 페이지씩 들어갈 수 있도록 전처리\n",
    "    save_path = \"processing_pdf/{}\".format(\"/\".join(path.parts[-2:]))\n",
    "    Path(save_path).parents[0].mkdir(parents=True,exist_ok=True)\n",
    "    doc = fitz.open(path)\n",
    "    output_doc = fitz.open()\n",
    "    for i in range(len(doc)) :\n",
    "        page = doc.load_page(i)\n",
    "        rect = page.rect\n",
    "        if i == 0 :\n",
    "            base_width = rect.width\n",
    "        \n",
    "        width = rect.width\n",
    "        height = rect.height\n",
    "        mid_x = width/2\n",
    "        if width != base_width :\n",
    "            left_rect = fitz.Rect(0,0,mid_x,height)\n",
    "            left_page = output_doc.new_page(width=mid_x,height=height)\n",
    "            left_page.show_pdf_page(left_rect,doc,i,clip=left_rect)\n",
    "\n",
    "            right_rect = fitz.Rect(width-mid_x,0,width,height)\n",
    "            right_page = output_doc.new_page(width=width-mid_x,height=height)\n",
    "            right_page.show_pdf_page(left_rect,doc,i,clip=right_rect)\n",
    "        else :\n",
    "            full_page = output_doc.new_page(width=width,height=height)\n",
    "            full_page.show_pdf_page(rect,doc,i)\n",
    "    output_doc.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f860a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"open/train.csv\")\n",
    "df_train[\"Source_path\"] = df_train[\"Source_path\"].map(lambda x: Path(x[2:]))\n",
    "df_train[\"processing_pdf_path\"] = df_train[\"Source_path\"].map(lambda x: Path(\"processing_pdf\") / x)\n",
    "\n",
    "df_test = pd.read_csv(\"open/test.csv\")\n",
    "df_test[\"Source_path\"] = df_test[\"Source_path\"].map(lambda x: Path(x[2:]))\n",
    "df_test[\"processing_pdf_path\"] = df_test[\"Source_path\"].map(lambda x: Path(\"processing_pdf\") / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da8e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in df_train[\"Source_path\"].unique() :\n",
    "#     processing_pdf(Path(\"open\") / path)\n",
    "\n",
    "# for path in df_test[\"Source_path\"].unique() :\n",
    "#     processing_pdf(Path(\"open\") / path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc35180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_lst = [Path(filename) for filename in df_train[\"processing_pdf_path\"].unique()]\n",
    "TRAIN_ENCODE_DIC = {\n",
    "    f\"train_docs_{i+1:04.0f}\":filename.stem for i,filename in enumerate(pdf_file_lst)\n",
    "}\n",
    "TRAIN_DECODE_DIC = {\n",
    "    filename.stem:f\"train_docs_{i+1:04.0f}\" for i,filename in enumerate(pdf_file_lst)\n",
    "}\n",
    "test_pdf_file_lst = [Path(filename) for filename in df_test[\"processing_pdf_path\"].unique()]\n",
    "TEST_ENCODE_DIC = {\n",
    "    f\"test_docs_{i+1:04.0f}\":filename.stem for i, filename in enumerate(test_pdf_file_lst)\n",
    "}\n",
    "TEST_DECODE_DIC = {\n",
    "    filename.stem:f\"test_docs_{i+1:04.0f}\" for i, filename in enumerate(test_pdf_file_lst)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71bf9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_docs_0001': '1-1 2024 주요 재정통계 1권',\n",
       " 'train_docs_0002': '2024 나라살림 예산개요',\n",
       " 'train_docs_0003': '재정통계해설',\n",
       " 'train_docs_0004': '국토교통부_전세임대(융자)',\n",
       " 'train_docs_0005': '고용노동부_청년일자리창출지원',\n",
       " 'train_docs_0006': '고용노동부_내일배움카드(일반)',\n",
       " 'train_docs_0007': '보건복지부_노인일자리 및 사회활동지원',\n",
       " 'train_docs_0008': '중소벤처기업부_창업사업화지원',\n",
       " 'train_docs_0009': '보건복지부_생계급여',\n",
       " 'train_docs_0010': '국토교통부_소규모주택정비사업',\n",
       " 'train_docs_0011': '국토교통부_민간임대(융자)',\n",
       " 'train_docs_0012': '고용노동부_조기재취업수당',\n",
       " 'train_docs_0013': '2024년도 성과계획서(총괄편)',\n",
       " 'train_docs_0014': '23-3호 조세지출 연계관리',\n",
       " 'train_docs_0015': '22-3호 재정융자사업',\n",
       " 'train_docs_0016': '월간 나라재정 2023년 12월호'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_ENCODE_DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05845e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"BM-K/KoSimCSE-roberta-multitask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc50eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea10793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qdrant(collection_name,data,embeddings) :\n",
    "    if Path(f\"db/{collection_name}\").exists() :\n",
    "        qdrant = Qdrant.from_existing_collection(\n",
    "            embedding=embeddings,\n",
    "            path=f\"db/{collection_name}\",\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "    else :\n",
    "        docs = [Document(page_content=line,metadata={\"idx\":i}) for i, line in enumerate(data)]\n",
    "        qdrant = Qdrant.from_documents(\n",
    "            docs,\n",
    "            embeddings,\n",
    "            path=f\"db/{collection_name}\",\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "    return qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e87a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename: train_docs_0016: 100%|██████████| 16/16 [00:04<00:00,  3.76it/s]\n"
     ]
    }
   ],
   "source": [
    "DB = {}\n",
    "DOCS = {}\n",
    "pbar = tqdm(pdf_file_lst)\n",
    "for filename in pbar :\n",
    "    decode_filename = TRAIN_DECODE_DIC[filename.stem]\n",
    "    pbar.set_description(f\"Filename: {decode_filename}\")\n",
    "    docs = fitz.open(filename)\n",
    "    \n",
    "    docs2text = []\n",
    "    docs_lst = []\n",
    "    for i in range(len(docs)) :\n",
    "        page = docs.load_page(i)\n",
    "        page2text = page.get_text()\n",
    "        page2line = sent_tokenize(page2text)\n",
    "        docs2text.extend(page2line)\n",
    "        docs_lst.append(f\"Page: {i+1}\\n{page2text}\")\n",
    "    DOCS[decode_filename] = docs_lst\n",
    "\n",
    "    if decode_filename not in DB :\n",
    "        DB[decode_filename] = initialize_qdrant(decode_filename,docs2text,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e530133f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_chat_completion(messages) :\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    output = model.generate(\n",
    "        input_ids.to(DEVICE),\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=128\n",
    "    )\n",
    "    return tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "860d8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table detecting: train_docs_0001\n"
     ]
    }
   ],
   "source": [
    "with open(\"template/table_detector.md\",\"r\",encoding=\"utf-8\") as f :\n",
    "    template = f.read()\n",
    "\n",
    "table_dic = {}\n",
    "for filename in pdf_file_lst :\n",
    "    decode_filename = TRAIN_DECODE_DIC[filename.stem]\n",
    "    print(f\"Table detecting: {decode_filename}\")\n",
    "    prompt = template.format(\n",
    "        filename=filename,\n",
    "        source=\"\\n\\n\".join(DOCS[decode_filename])\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"너는 글을 보고 목차를 만들어주는 역할이야. 글의 내용을 보고, 목차에 맞춰서 페이지 할당해줘.\"},\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    "    response = create_chat_completion(messages)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5d63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
